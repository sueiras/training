{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic commands in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "#Basic interactive session\n",
    "\n",
    "# Enter an interactive TensorFlow Session.\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Define a var and a constant\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# Initialize the var 'x' using the run() method\n",
    "x.initializer.run()\n",
    "\n",
    "# Add an op to subtract 'a' from 'x'.  Run it and print the result\n",
    "sub = tf.sub(x, a)\n",
    "print(sub.eval())\n",
    "# ==> [-2. -1.]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear model in a interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get some data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/home/ubuntu/data/training/image/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  1.81275\n",
      "1  -  1.60889\n",
      "2  -  1.30185\n",
      "3  -  1.24295\n",
      "4  -  1.06077\n",
      "5  -  1.02548\n",
      "6  -  0.837058\n",
      "7  -  0.813003\n",
      "8  -  0.772033\n",
      "9  -  0.794147\n",
      "10  -  0.708654\n",
      "11  -  0.657701\n",
      "12  -  0.60068\n",
      "13  -  0.668502\n",
      "14  -  0.660577\n",
      "15  -  0.734497\n",
      "16  -  0.689952\n",
      "17  -  0.687497\n",
      "18  -  0.709138\n",
      "19  -  0.654925\n",
      "20  -  0.704622\n",
      "21  -  0.547344\n",
      "22  -  0.595498\n",
      "23  -  0.440265\n",
      "24  -  0.497913\n",
      "25  -  0.601578\n",
      "26  -  0.51206\n",
      "27  -  0.505472\n",
      "28  -  0.510493\n",
      "29  -  0.418059\n"
     ]
    }
   ],
   "source": [
    "# Interactive session for train a model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Declare input variables\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "#Trainable variables\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#Model\n",
    "y_pred = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# Loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))\n",
    "\n",
    "# Trainer\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "#Loop to train the model. 30 batches of 100 cases\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(30):\n",
    "    batch = mnist.train.next_batch(500)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "    print(i, ' - ',cross_entropy.eval(feed_dict={x: batch[0], y: batch[1]}))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06907193  0.135791   -0.0294337  -0.04222807  0.04624839  0.073547\n",
      "  0.00773067  0.06736173 -0.17107926 -0.01886572]\n",
      "0.295497\n",
      "[[ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate variables\n",
    "\n",
    "# Evaluata trainable variables\n",
    "print(b.eval())\n",
    "print(np.max(W.eval()))\n",
    "\n",
    "# Evaluate results variables\n",
    "print(y.eval(feed_dict={x: batch[0], y: batch[1]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic usage in batch mode\n",
    "\n",
    "# Define a graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # graph definition\n",
    "    \n",
    "    \n",
    "# Execute a graph to train a network\n",
    "with tf.Session(graph=graph) as session:\n",
    "    print('Initializing')\n",
    "    tf.initialize_all_variables().run()\n",
    "    for epoch in range(nEpochs):\n",
    "        for batch in batch_list:\n",
    "            feedDict = {} # dictionary of batch data to run the graph\n",
    "            _, param1_out, param2_out = session.run([optimizer, param1_in, param2_in], feed_dict=feedDict)\n",
    "    \n",
    "    \n",
    "# Execute a graph to score data  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SELECT DEVICE\n",
    "with tf.device('/cpu:0'):\n",
    "    # Include here the graph operations for the CPU.\n",
    "\n",
    "\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "\n",
    "# LIMIT THE MEMORY OF THE GPU\n",
    "# Assume that you have 12GB of GPU memory and want to allocate ~4GB:\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of variables saved in a model file\n",
    "path_model = '/home/jorge/data/tesis/handwriting/p05_ctc/IAM_corleone_first_model/'\n",
    "reader = tf.train.NewCheckpointReader(path_model + \"modelCTC_original_images_01_epoch_95.ckpt\")\n",
    "print(reader.debug_string().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Accuracy test 0.8834\n"
     ]
    }
   ],
   "source": [
    "# Create and save model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Define graph\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name='y')\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "#Prediction\n",
    "y_pred = tf.nn.softmax(tf.matmul(x,W) + b, name='y_pred')\n",
    "\n",
    "#Loss\n",
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_pred), name='cross_entropy')\n",
    "\n",
    "# Train graph\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01, name='train_step').minimize(cross_entropy)\n",
    "\n",
    "\n",
    "# Inicialize graph vars\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(100):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "# Predict and evaluate    \n",
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='Accuracy')\n",
    "\n",
    "print('Accuracy test', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "\n",
    "# Add to the collection the vars that we need in the future\n",
    "\n",
    "# - For train: all the placeholders and the train_step\n",
    "#tf.add_to_collection('x', x)\n",
    "#tf.add_to_collection('y', y)\n",
    "#tf.add_to_collection('train_step', train_step)\n",
    "\n",
    "# - For score: X placeholders and y_pred\n",
    "#tf.add_to_collection('x', x)\n",
    "#tf.add_to_collection('y_pred', y_pred)\n",
    "\n",
    "# - For validation: All placeholders and loss & accuracy\n",
    "#tf.add_to_collection('x', x)\n",
    "#tf.add_to_collection('y', y)\n",
    "#tf.add_to_collection('cross_entropy', cross_entropy)\n",
    "#tf.add_to_collection('accuracy', accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Create a saver and save weigths.\n",
    "saver = tf.train.Saver(max_to_keep=0)\n",
    "saver.save(sess, '/tmp/my-model',)\n",
    "\n",
    "\n",
    "#Close session\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Tensor(\"Accuracy:0\", shape=(), dtype=float32)\n",
      "('Accuracy test', 0.90740007)\n"
     ]
    }
   ],
   "source": [
    "# Continue training a model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Load model\n",
    "new_saver = tf.train.import_meta_graph('/tmp/my-model.meta')\n",
    "new_saver.restore(sess, '/tmp/my-model')\n",
    "\n",
    "#Load vars\n",
    "#x = tf.get_collection('x')[0]\n",
    "#y = tf.get_collection('y')[0]\n",
    "\n",
    "#Continue training\n",
    "train_step = tf.get_collection('train_step')[0]\n",
    "for i in range(900):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "    accuracy = tf.get_collection('accuracy')[0]\n",
    "\n",
    "print('Accuracy test', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('Prediction test', array([[  6.45731576e-04,   1.06451043e-05,   3.88225482e-04,\n",
      "          2.63259769e-03,   3.83650011e-04,   2.99013918e-04,\n",
      "          1.43197049e-05,   9.90874648e-01,   3.23611312e-04,\n",
      "          4.42757038e-03],\n",
      "       [  1.20471008e-01,   9.97607596e-04,   6.55485213e-01,\n",
      "          2.02858914e-02,   3.41765963e-06,   4.09900211e-02,\n",
      "          1.40440777e-01,   3.72032150e-06,   2.12676339e-02,\n",
      "          5.46845840e-05]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Score new data\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load data\n",
    "data_path = '/home/jorge/data/training/tensorflow/'\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(data_path + 'MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Load model\n",
    "new_saver = tf.train.import_meta_graph('/tmp/my-model.meta')\n",
    "new_saver.restore(sess, '/tmp/my-model')\n",
    "\n",
    "#Load vars\n",
    "x = tf.get_collection('x')[0]\n",
    "y_pred = tf.get_collection('y_pred')[0]\n",
    "\n",
    "print('Prediction test', y_pred.eval(feed_dict={x: mnist.test.images[0:2]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/jorge/data/training/tensorflow/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('cross_entropy test', 4099.9136)\n",
      "('Accuracy test', 0.88340008)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Load data\n",
    "data_path = '/home/jorge/data/training/tensorflow/'\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(data_path + 'MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Load model\n",
    "new_saver = tf.train.import_meta_graph('/tmp/my-model.meta')\n",
    "new_saver.restore(sess, '/tmp/my-model')\n",
    "\n",
    "#Load vars\n",
    "x = tf.get_collection('x')[0]\n",
    "y = tf.get_collection('y')[0]\n",
    "\n",
    "accuracy = tf.get_collection('accuracy')[0]\n",
    "cross_entropy = tf.get_collection('cross_entropy')[0]\n",
    "print('cross_entropy test', cross_entropy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "print('Accuracy test', accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model as pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "### create some graph here ###\n",
    "##############################\n",
    "\n",
    "graph_def = sess.graph.as_graph_def()\n",
    "output_node_names = \"output0,output1\" # put the names of the output nodes here\n",
    "\n",
    "# freeze all parameters and save\n",
    "output_graph_def = graph_util.convert_variables_to_constants(\n",
    "        sess, graph_def, output_node_names.split(\",\"))\n",
    "with tf.gfile.GFile(output_graph_file, \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Model Benchmark Tool\n",
    "\n",
    "1 build the binary:\n",
    "<code>\n",
    "$bazel build -c opt tensorflow/tools/benchmark:benchmark_model\n",
    "</code>\n",
    "\n",
    "2 Run on your compute graph:\n",
    "<code>\n",
    "$bazel-bin/tensorflow/tools/benchmark/benchmark_model \\\n",
    "  --graph=tensorflow_inception_graph.pb \\\n",
    "  --input_layer=\"input:0\" \\\n",
    "  --input_layer_shape=\"1,224,224,3\" \\\n",
    "  --input_layer_type=\"float\" \\\n",
    "  --output_layer=\"output:0\"\n",
    "</code>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
