{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to tensor flow\n",
    " - Basic models over MNIST dataset\n",
    "   - Linear model\n",
    "   - NN one layer node\n",
    "   - Convolutional model\n",
    " - Tensoboard example\n",
    " - Save & load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  1.2.1\n"
     ]
    }
   ],
   "source": [
    "# Header\n",
    "# Basic libraries & options\n",
    "from __future__ import print_function\n",
    "\n",
    "#Basic libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "import time\n",
    "\n",
    "# Select GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "#Show images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt configuration\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # size of images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # show exact image\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import datasets, layers, models, optimizers\n",
    "\n",
    "# Data\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path='mnist.npz')\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s - loss: 1.1490 - acc: 0.7427 - val_loss: 0.6084 - val_acc: 0.8648\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.5258 - acc: 0.8734 - val_loss: 0.4332 - val_acc: 0.8935\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.4200 - acc: 0.8914 - val_loss: 0.3716 - val_acc: 0.9029\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3727 - acc: 0.9000 - val_loss: 0.3379 - val_acc: 0.9108\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3439 - acc: 0.9056 - val_loss: 0.3158 - val_acc: 0.9147\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3234 - acc: 0.9112 - val_loss: 0.2997 - val_acc: 0.9185\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3078 - acc: 0.9150 - val_loss: 0.2864 - val_acc: 0.9217\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2945 - acc: 0.9184 - val_loss: 0.2768 - val_acc: 0.9244\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2834 - acc: 0.9216 - val_loss: 0.2665 - val_acc: 0.9268\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2737 - acc: 0.9245 - val_loss: 0.2584 - val_acc: 0.9283\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2649 - acc: 0.9264 - val_loss: 0.2520 - val_acc: 0.9294\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2571 - acc: 0.9286 - val_loss: 0.2448 - val_acc: 0.9316\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2498 - acc: 0.9306 - val_loss: 0.2388 - val_acc: 0.9321\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2432 - acc: 0.9325 - val_loss: 0.2335 - val_acc: 0.9341\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2369 - acc: 0.9341 - val_loss: 0.2274 - val_acc: 0.9370\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2311 - acc: 0.9365 - val_loss: 0.2228 - val_acc: 0.9377\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2254 - acc: 0.9380 - val_loss: 0.2180 - val_acc: 0.9384\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2203 - acc: 0.9394 - val_loss: 0.2139 - val_acc: 0.9393\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2153 - acc: 0.9411 - val_loss: 0.2098 - val_acc: 0.9412\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2106 - acc: 0.9420 - val_loss: 0.2055 - val_acc: 0.9420\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2062 - acc: 0.9433 - val_loss: 0.2013 - val_acc: 0.9433\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2019 - acc: 0.9444 - val_loss: 0.1972 - val_acc: 0.9449\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1977 - acc: 0.9454 - val_loss: 0.1936 - val_acc: 0.9446\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1937 - acc: 0.9469 - val_loss: 0.1911 - val_acc: 0.9466\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1899 - acc: 0.9480 - val_loss: 0.1875 - val_acc: 0.9469\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1863 - acc: 0.9489 - val_loss: 0.1838 - val_acc: 0.9472\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1827 - acc: 0.9499 - val_loss: 0.1812 - val_acc: 0.9484\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1794 - acc: 0.9510 - val_loss: 0.1781 - val_acc: 0.9494\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1762 - acc: 0.9518 - val_loss: 0.1754 - val_acc: 0.9493\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1730 - acc: 0.9525 - val_loss: 0.1726 - val_acc: 0.9511\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1701 - acc: 0.9534 - val_loss: 0.1699 - val_acc: 0.9513\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1671 - acc: 0.9540 - val_loss: 0.1678 - val_acc: 0.9523\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1642 - acc: 0.9546 - val_loss: 0.1655 - val_acc: 0.9531\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1615 - acc: 0.9560 - val_loss: 0.1628 - val_acc: 0.9526\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1589 - acc: 0.9562 - val_loss: 0.1602 - val_acc: 0.9542\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1563 - acc: 0.9570 - val_loss: 0.1583 - val_acc: 0.9547\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1538 - acc: 0.9575 - val_loss: 0.1562 - val_acc: 0.9548\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1514 - acc: 0.9584 - val_loss: 0.1541 - val_acc: 0.9567\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1490 - acc: 0.9588 - val_loss: 0.1516 - val_acc: 0.9569\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1468 - acc: 0.9594 - val_loss: 0.1503 - val_acc: 0.9567\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1446 - acc: 0.9598 - val_loss: 0.1478 - val_acc: 0.9573\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1424 - acc: 0.9607 - val_loss: 0.1467 - val_acc: 0.9578\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1403 - acc: 0.9612 - val_loss: 0.1447 - val_acc: 0.9584\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1383 - acc: 0.9619 - val_loss: 0.1428 - val_acc: 0.9595\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1363 - acc: 0.9624 - val_loss: 0.1408 - val_acc: 0.9592\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1344 - acc: 0.9628 - val_loss: 0.1393 - val_acc: 0.9592\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1324 - acc: 0.9638 - val_loss: 0.1375 - val_acc: 0.9602\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1307 - acc: 0.9641 - val_loss: 0.1367 - val_acc: 0.9595\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1289 - acc: 0.9647 - val_loss: 0.1348 - val_acc: 0.9601\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1271 - acc: 0.9653 - val_loss: 0.1339 - val_acc: 0.9605\n"
     ]
    }
   ],
   "source": [
    "# Base Keras Model\n",
    "images = layers.Input(batch_shape=(None, 28, 28), dtype='float32', name='Images')\n",
    "\n",
    "flat   = layers.Flatten(name='Flat_image')(images)\n",
    "dense  = layers.Dense(500, activation='relu', name='Dense_layer')(flat)\n",
    "output = layers.Dense(10, activation='softmax', name='Dense_output')(dense)\n",
    "\n",
    "model_linear = models.Model(inputs=images, outputs=output)\n",
    "\n",
    "# Train\n",
    "sgd_optimizer = optimizers.SGD(lr=0.01)\n",
    "model_linear.compile(loss='sparse_categorical_crossentropy',\n",
    "                     optimizer=optimizers.SGD(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "history_linear = model_linear.fit(X_train, y_train, batch_size=128, epochs=50,\n",
    "                                  verbose=1, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow control the training proccess\n",
    "    - use a batch generator\n",
    "    - Implement a basic training process\n",
    "        - Create placeholders\n",
    "        - Create a loss function\n",
    "        - Create a trainer\n",
    "        - Define an accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define input placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None, ])\n",
    "\n",
    "# Define model using Keras layers\n",
    "flat   = layers.Flatten(name='Flat_image')(x)\n",
    "dense  = layers.Dense(500, activation='relu', name='Dense_layer')(flat)\n",
    "output = layers.Dense(10, activation='relu', name='Dense_output')(dense)\n",
    "\n",
    "# Define the Tensorflow Loss\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(y, output)\n",
    "\n",
    "# Define the Tensorflow Train function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Create an Accuracy metric to evaluate in test\n",
    "y_pred = tf.nn.softmax(output)\n",
    "correct_prediction = tf.equal(y, tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a generator to data. Same code to an HDF5 source\n",
    "def batch_generator(X, y, batch_size=64):\n",
    "    data_size = X.shape[0]\n",
    "    # Randomize batches in each epoch\n",
    "    batch_randomized = np.random.permutation(range(0, data_size-batch_size, batch_size))\n",
    "    # Iterate over each batch\n",
    "    for batch in batch_randomized:\n",
    "        x_batch = X[batch : batch+batch_size]\n",
    "        y_batch = y[batch : batch+batch_size]\n",
    "        yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7793\n",
      "1 0.8753\n",
      "2 0.8957\n",
      "3 0.9063\n",
      "4 0.9112\n",
      "5 0.9154\n",
      "6 0.9198\n",
      "7 0.9217\n",
      "8 0.9243\n",
      "9 0.9266\n",
      "10 0.9301\n",
      "11 0.931\n",
      "12 0.9321\n",
      "13 0.933\n",
      "14 0.9351\n",
      "15 0.9366\n",
      "16 0.9384\n",
      "17 0.9392\n",
      "18 0.9406\n",
      "19 0.9408\n",
      "20 0.9437\n",
      "21 0.9427\n",
      "22 0.9446\n",
      "23 0.9449\n",
      "24 0.9478\n",
      "25 0.948\n",
      "26 0.9488\n",
      "27 0.9499\n",
      "28 0.9515\n",
      "29 0.9509\n",
      "30 0.9529\n",
      "31 0.9538\n",
      "32 0.9544\n",
      "33 0.9537\n",
      "34 0.9543\n",
      "35 0.9554\n",
      "36 0.9549\n",
      "37 0.956\n",
      "38 0.9571\n",
      "39 0.9574\n",
      "40 0.9577\n",
      "41 0.9582\n",
      "42 0.9582\n",
      "43 0.9587\n",
      "44 0.9592\n",
      "45 0.9605\n",
      "46 0.9608\n",
      "47 0.9606\n",
      "48 0.9611\n",
      "49 0.9623\n"
     ]
    }
   ],
   "source": [
    "# Basic iterator over the epochs and the batches to execute the trainer. \n",
    "batch_size = 128\n",
    "num_epoch = 50\n",
    "for epoch in range(num_epoch):\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "    print(epoch, accuracy.eval(feed_dict={x: X_test, y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Accuracy:  0.9235\n",
      "Epoch:  20 Accuracy:  0.939\n",
      "Epoch:  30 Accuracy:  0.9491\n",
      "Epoch:  40 Accuracy:  0.9559\n",
      "Epoch:  50 Accuracy:  0.96\n",
      "Epoch:  60 Accuracy:  0.9647\n",
      "Epoch:  70 Accuracy:  0.9664\n",
      "Epoch:  80 Accuracy:  0.9689\n",
      "Epoch:  90 Accuracy:  0.9704\n",
      "Epoch:  100 Accuracy:  0.9722\n",
      "Epoch:  110 Accuracy:  0.9736\n",
      "Epoch:  120 Accuracy:  0.9747\n",
      "Epoch:  130 Accuracy:  0.9753\n",
      "Epoch:  140 Accuracy:  0.9763\n",
      "Epoch:  150 Accuracy:  0.977\n",
      "Epoch:  160 Accuracy:  0.9775\n",
      "Epoch:  170 Accuracy:  0.9782\n",
      "Epoch:  180 Accuracy:  0.9786\n",
      "STOP. Accuracy:  0.9779\n"
     ]
    }
   ],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Early stopping code. Stop if the current accuray is < that the min of the last 5 epochs. \n",
    "batch_size = 128\n",
    "acc_test=[]\n",
    "epoch=0\n",
    "stop=True\n",
    "\n",
    "while stop:\n",
    "    #Train\n",
    "    epoch += 1\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "    # Test\n",
    "    acc_test += [accuracy.eval(feed_dict={x: X_test, y: y_test})]\n",
    "    if epoch%10==0:\n",
    "        print('Epoch: ', epoch, 'Accuracy: ', acc_test[-1])\n",
    "\n",
    "    # Stopping criteria\n",
    "    if epoch>10 and acc_test[-1] < min(acc_test[-10:-1]):\n",
    "        stop=False\n",
    "        print('STOP. Accuracy: ', acc_test[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When finish, close the interactive session\n",
    "sess.close()\n",
    "\n",
    "# Reset the graph to the next experiments\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow layers and tensorboard\n",
    "    - Combine Keras layers with tensorflow layers\n",
    "    - Monitor layers in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat layer:  Tensor(\"Flat_image/Reshape:0\", shape=(?, 320), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# Convolutional model\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None, ])\n",
    "\n",
    "image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "conv1 = layers.Conv2D(20, (5,5))(image)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(20, (5,5))(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "flat = layers.Flatten(name='Flat_image')(pool2)\n",
    "print('Flat layer: ', flat)\n",
    "\n",
    "\n",
    "# Tensorflow Dense layer\n",
    "W_dense = tf.Variable(tf.truncated_normal([320, 500], stddev=0.1), name='W_dense')\n",
    "b_dense = tf.Variable(tf.constant(0.1, shape=[500]), name='b_dense')\n",
    "dense1 = tf.nn.relu(tf.matmul(flat, W_dense) + b_dense)\n",
    "#dense1 = layers.Dense(500, activation='relu', name='Dense_1')(flat)\n",
    "\n",
    "\n",
    "output = layers.Dense(10, activation='linear', name='Dense_output')(dense1)\n",
    "\n",
    "# Define the Tensorflow Loss\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(y, output)\n",
    "\n",
    "# Define the Tensorflow Train function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Create an Accuracy metric to evaluate in test\n",
    "y_pred = tf.nn.softmax(output)\n",
    "correct_prediction = tf.equal(y, tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Accuracy:  0.9047\n",
      "Epoch:  2 Accuracy:  0.9381\n",
      "Epoch:  3 Accuracy:  0.9549\n",
      "Epoch:  4 Accuracy:  0.9639\n",
      "Epoch:  5 Accuracy:  0.9676\n",
      "Epoch:  6 Accuracy:  0.9726\n",
      "Epoch:  7 Accuracy:  0.973\n",
      "Epoch:  8 Accuracy:  0.9761\n",
      "Epoch:  9 Accuracy:  0.9758\n",
      "Epoch:  10 Accuracy:  0.979\n",
      "Epoch:  11 Accuracy:  0.9769\n",
      "Epoch:  12 Accuracy:  0.9803\n",
      "Epoch:  13 Accuracy:  0.9802\n",
      "Epoch:  14 Accuracy:  0.9813\n",
      "Epoch:  15 Accuracy:  0.9818\n",
      "Epoch:  16 Accuracy:  0.9816\n",
      "Epoch:  17 Accuracy:  0.9823\n",
      "Epoch:  18 Accuracy:  0.9833\n",
      "Epoch:  19 Accuracy:  0.9824\n",
      "Epoch:  20 Accuracy:  0.984\n",
      "Epoch:  21 Accuracy:  0.9828\n",
      "Epoch:  22 Accuracy:  0.9847\n",
      "Epoch:  23 Accuracy:  0.985\n",
      "Epoch:  24 Accuracy:  0.9842\n",
      "Epoch:  25 Accuracy:  0.9854\n",
      "Epoch:  26 Accuracy:  0.984\n",
      "Epoch:  27 Accuracy:  0.9854\n",
      "Epoch:  28 Accuracy:  0.9848\n",
      "Epoch:  29 Accuracy:  0.9857\n",
      "Epoch:  30 Accuracy:  0.9861\n",
      "Epoch:  31 Accuracy:  0.9851\n",
      "Epoch:  32 Accuracy:  0.9856\n",
      "Epoch:  33 Accuracy:  0.9852\n",
      "Epoch:  34 Accuracy:  0.9873\n",
      "Epoch:  35 Accuracy:  0.986\n",
      "Epoch:  36 Accuracy:  0.9859\n",
      "Epoch:  37 Accuracy:  0.9869\n",
      "Epoch:  38 Accuracy:  0.9867\n",
      "Epoch:  39 Accuracy:  0.986\n",
      "Epoch:  40 Accuracy:  0.9859\n",
      "Epoch:  41 Accuracy:  0.9864\n",
      "Epoch:  42 Accuracy:  0.986\n",
      "Epoch:  43 Accuracy:  0.9867\n",
      "Epoch:  44 Accuracy:  0.9874\n",
      "Epoch:  45 Accuracy:  0.9867\n",
      "Epoch:  46 Accuracy:  0.9872\n",
      "Epoch:  47 Accuracy:  0.9868\n",
      "Epoch:  48 Accuracy:  0.9872\n",
      "Epoch:  49 Accuracy:  0.9877\n",
      "Epoch:  50 Accuracy:  0.9876\n",
      "Epoch:  51 Accuracy:  0.9871\n",
      "Epoch:  52 Accuracy:  0.9873\n",
      "Epoch:  53 Accuracy:  0.9866\n",
      "STOP. Accuracy:  0.9866\n"
     ]
    }
   ],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Early stopping code. Stop if the current accuray is < that the min of the last 5 epochs. \n",
    "batch_size = 128\n",
    "acc_test=[]\n",
    "epoch=0\n",
    "stop=True\n",
    "\n",
    "while stop:\n",
    "    #Train\n",
    "    epoch += 1\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "    # Test\n",
    "    acc_test += [accuracy.eval(feed_dict={x: X_test, y: y_test})]\n",
    "    if epoch%1==0:\n",
    "        print('Epoch: ', epoch, 'Accuracy: ', acc_test[-1])\n",
    "\n",
    "    # Stopping criteria\n",
    "    if epoch>10 and acc_test[-1] < min(acc_test[-10:-1]):\n",
    "        stop=False\n",
    "        print('STOP. Accuracy: ', acc_test[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When finish, close the interactive session\n",
    "sess.close()\n",
    "\n",
    "# Reset the graph to the next experiments\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tensorboard to show the net & the training process.\n",
    "    - The same previous convolutional model with the commands that need tensorboard\n",
    "\n",
    "Based on https://www.tensorflow.org/how_tos/summaries_and_tensorboard/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/'   + name, mean)\n",
    "        tf.summary.scalar('sttdev/' + name, tf.sqrt(tf.reduce_mean(tf.square(var - mean))))\n",
    "        tf.summary.scalar('max/'    + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/'    + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram(name, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# Convolutional model\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None, ])\n",
    "\n",
    "image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "with tf.name_scope('Conv1') as scope:\n",
    "    conv1 = layers.Conv2D(20, (5,5))(image)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    variable_summaries(pool1, \"pool1_summary\")\n",
    "\n",
    "with tf.name_scope('Conv2') as scope:\n",
    "    conv2 = layers.Conv2D(20, (5,5))(pool1)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    variable_summaries(pool2, \"pool2_summary\")\n",
    "\n",
    "with tf.name_scope('Dense') as scope:\n",
    "    flat = layers.Flatten(name='Flat_image')(pool2)\n",
    "    # Tensorflow Dense layer\n",
    "    W_dense = tf.Variable(tf.truncated_normal([320, 500], stddev=0.1), name='W_dense')\n",
    "    variable_summaries(W_dense, \"W_dense_summary\") # Summaries of the layer weigths\n",
    "    b_dense = tf.Variable(tf.constant(0.1, shape=[500]), name='b_dense')\n",
    "    variable_summaries(b_dense, \"b_dense_summary\") # Summaries of the layer weigths\n",
    "    dense1 = tf.nn.relu(tf.matmul(flat, W_dense) + b_dense)\n",
    "    variable_summaries(dense1, \"dense1_summary\") # Summaries of the layer output\n",
    "\n",
    "    output = layers.Dense(10, activation='linear', name='Dense_output')(dense1)\n",
    "\n",
    "# Define the Tensorflow Loss\n",
    "#with tf.name_scope('loss') as scope:\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(y, output)\n",
    "loss_summary = tf.summary.scalar(\"loss\", cross_entropy)\n",
    "    \n",
    "# Define the Tensorflow Train function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Create an Accuracy metric to evaluate in test\n",
    "#with tf.name_scope('acc') as scope:\n",
    "y_pred = tf.nn.softmax(output)\n",
    "correct_prediction = tf.equal(y, tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy_summary = tf.summary.scalar(\"acc\", accuracy)\n",
    "\n",
    "# Add summaries to the graph\n",
    "summaries_dir = '/tmp/tensorboard/tf'\n",
    "with tf.name_scope('summaries') as scope:\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train', sess.graph)\n",
    "    test_writer  = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Accuracy:  0.9169\n",
      "Epoch:  2 Accuracy:  0.9417\n",
      "Epoch:  3 Accuracy:  0.9528\n",
      "Epoch:  4 Accuracy:  0.9624\n",
      "Epoch:  5 Accuracy:  0.9667\n",
      "Epoch:  6 Accuracy:  0.9668\n",
      "Epoch:  7 Accuracy:  0.9739\n",
      "Epoch:  8 Accuracy:  0.975\n",
      "Epoch:  9 Accuracy:  0.9761\n",
      "Epoch:  10 Accuracy:  0.9788\n",
      "Epoch:  11 Accuracy:  0.9794\n",
      "Epoch:  12 Accuracy:  0.9794\n",
      "Epoch:  13 Accuracy:  0.9794\n",
      "Epoch:  14 Accuracy:  0.9787\n",
      "Epoch:  15 Accuracy:  0.9806\n",
      "Epoch:  16 Accuracy:  0.9829\n",
      "Epoch:  17 Accuracy:  0.9826\n",
      "Epoch:  18 Accuracy:  0.9841\n",
      "Epoch:  19 Accuracy:  0.9841\n",
      "Epoch:  20 Accuracy:  0.9849\n",
      "Epoch:  21 Accuracy:  0.9834\n",
      "Epoch:  22 Accuracy:  0.9861\n",
      "Epoch:  23 Accuracy:  0.9851\n",
      "Epoch:  24 Accuracy:  0.9859\n",
      "Epoch:  25 Accuracy:  0.9852\n",
      "Epoch:  26 Accuracy:  0.9869\n",
      "Epoch:  27 Accuracy:  0.9855\n",
      "Epoch:  28 Accuracy:  0.9852\n",
      "Epoch:  29 Accuracy:  0.9842\n",
      "Epoch:  30 Accuracy:  0.9867\n",
      "Epoch:  31 Accuracy:  0.9843\n",
      "Epoch:  32 Accuracy:  0.987\n",
      "Epoch:  33 Accuracy:  0.9861\n",
      "Epoch:  34 Accuracy:  0.9877\n",
      "Epoch:  35 Accuracy:  0.9871\n",
      "Epoch:  36 Accuracy:  0.9869\n",
      "Epoch:  37 Accuracy:  0.9863\n",
      "Epoch:  38 Accuracy:  0.986\n",
      "Epoch:  39 Accuracy:  0.986\n",
      "Epoch:  40 Accuracy:  0.9875\n",
      "Epoch:  41 Accuracy:  0.987\n",
      "Epoch:  42 Accuracy:  0.9868\n",
      "Epoch:  43 Accuracy:  0.9859\n",
      "STOP. Accuracy:  0.9859\n"
     ]
    }
   ],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Early stopping code. Stop if the current accuray is < that the min of the last 5 epochs. \n",
    "batch_size = 128\n",
    "acc_test=[]\n",
    "epoch=0\n",
    "stop=True\n",
    "while stop:\n",
    "    #Train\n",
    "    epoch += 1\n",
    "    counter = 0\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "        \n",
    "        counter += 1\n",
    "        if counter%10 == 0:\n",
    "            summary_str = merged.eval(feed_dict={x: x_batch, y: y_batch}) #TENSORBOARD\n",
    "            train_writer.add_summary(summary_str, epoch) #TENSORBOARD\n",
    "            \n",
    "                \n",
    "    # Test\n",
    "    acc_test += [accuracy.eval(feed_dict={x: X_test, y: y_test})]\n",
    "    \n",
    "    summary_str = merged.eval(feed_dict={x: X_test, y: y_test}) #TENSORBOARD \n",
    "    test_writer.add_summary(summary_str, epoch) #TENSORBOARD \n",
    "      \n",
    "    if epoch%1==0:\n",
    "        print('Epoch: ', epoch, 'Accuracy: ', acc_test[-1])\n",
    "\n",
    "    # Stopping criteria\n",
    "    if epoch>10 and acc_test[-1] < min(acc_test[-10:-1]):\n",
    "        stop=False\n",
    "        print('STOP. Accuracy: ', acc_test[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end execute tensorboar with:\n",
    "\n",
    "    cd /tmp\n",
    "\n",
    "    tensorboard --logdir=./tensorboard\n",
    "\n",
    "And accest to it in:\n",
    "\n",
    "    http://<My_server_IP>:6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf12]",
   "language": "python",
   "name": "conda-env-tf12-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
