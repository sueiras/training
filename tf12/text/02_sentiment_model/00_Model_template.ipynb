{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model template\n",
    "    - Preprocess data.\n",
    "    - Prepare sequences to model.\n",
    "    - Build model.\n",
    "    - Validate it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Header\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "import time\n",
    "\n",
    "#Show images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt configuration\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # size of images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # show exact image\n",
    "#plt.rcParams['image.cmap'] = 'gray'  # use grayscale \n",
    "\n",
    "\n",
    "# GPU devices visible by python\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import train and test data\n",
    "data_path='/home/ubuntu/data/training/text/sentiment/aclImdb/'\n",
    "\n",
    "X_train = np.load(data_path + 'X_train.npy')\n",
    "y_train = np.load(data_path + 'y_train.npy')\n",
    "X_test  = np.load(data_path + 'X_test.npy')\n",
    "y_test  = np.load(data_path + 'y_test.npy')\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare sequences to model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 20000 # Number of most frequent words selected. the less frequent recode to 0\n",
    "max_len = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "\n",
    "\n",
    "#Select the most frequent max_features, recode others using 0\n",
    "def remove_features(x):\n",
    "    return [[0 if w >= max_features else w for w in sen] for sen in x]\n",
    "\n",
    "X_train = remove_features(X_train)\n",
    "X_test  = remove_features(X_test)\n",
    "\n",
    "\n",
    "# Cut or complete the sentences to length = maxlen\n",
    "from tensorflow.contrib.keras import preprocessing\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "dim_embedings = 128 #Dimension of the embedings vector\n",
    "num_hidden_rnn = 128 #Num of neurons in the Recurent network \n",
    "\n",
    "from tensorflow.contrib.keras import layers, models, optimizers\n",
    "\n",
    "print('Build model 1 - Basic model...')\n",
    "\n",
    "# LAYER 1: inputs\n",
    "seq_prev_input = layers.Input(shape=(max_len, ), dtype='int32') \n",
    "\n",
    "# LAYER 2: Create embedings\n",
    "embeds = layers.Embedding(max_features, dim_embedings, input_length=max_len)(seq_prev_input)\n",
    "\n",
    "# LAYERS 3: Model layers\n",
    "#------------------------\n",
    "# PUT YOUR MODEL HERE!!!\n",
    "#------------------------\n",
    "\n",
    "\n",
    "# LAYER 4: Dense layer to outputs - softmax activation\n",
    "output = layers.Dense(2, activation='softmax')(rnn_out)\n",
    "\n",
    "# Model Architecture defined\n",
    "model_1 = models.Model(inputs=seq_prev_input, outputs=output)\n",
    "model_1.summary()\n",
    "\n",
    "# Compile model and select optimizer\n",
    "rms_optimizer = optimizers.RMSprop(lr=0.001)\n",
    "model_1.compile(loss='sparse_categorical_crossentropy', optimizer=rms_optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the model graph\n",
    "from tensorflow.contrib.keras import utils\n",
    "\n",
    "# Create model image\n",
    "utils.plot_model(model_1, '/tmp/model1.png')\n",
    "\n",
    "# Show image\n",
    "plt.imshow(plt.imread('/tmp/model1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "batch_size = 128\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model_1.fit(X_train, y_train, batch_size=batch_size, epochs=10,\n",
    "                      validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot graphs in the notebook output\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score and obtain probabilities\n",
    "pred_test = model_1.predict(X_test)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import metrics\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "#Calculate accuracy with sklearn\n",
    "print(accuracy_score(y_test, [1 if p>0.5 else 0 for p in pred_test[:,1]]))\n",
    "\n",
    "#Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, pred_test[:,1])\n",
    "print('AUC: ', auc(fpr, tpr)  )\n",
    "\n",
    "#Plot ROC curve\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score new text\n",
    "\n",
    "# Load dictionary\n",
    "import pickle\n",
    "with open(data_path + 'worddict.pickle', 'rb') as pfile:\n",
    "    worddict = pickle.load(pfile)\n",
    "\n",
    "    \n",
    "def tokenize(sentences):\n",
    "    from nltk import word_tokenize\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        tokens += [word_tokenize(sentence)]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def generate_sequence(sentences, dictionary):\n",
    "    seqs = [None] * len(sentences)\n",
    "    for idx, ss in enumerate(sentences):\n",
    "        seqs[idx] = [dictionary[w] if w in dictionary else 1 for w in ss]\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def remove_features(x):\n",
    "    return [[0 if w >= max_features else w for w in sen] for sen in x]\n",
    "\n",
    "\n",
    "def score_new_text(text):\n",
    "    seq = generate_sequence(tokenize([text]), worddict)\n",
    "    seq = remove_features(seq)\n",
    "    seq = preprocessing.sequence.pad_sequences(seq, maxlen=max_len)\n",
    "    pred_test = model_1.predict(seq, batch_size=1)\n",
    "    return float(pred_test[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluate one negative record\n",
    "\n",
    "text = \"You have to start worrying when you see that Michael Madsen is leading the Cast of any movie. I wont go through the list of shame that is his movie career.<br /><br />I watched 45 minutes and still was not sure what really was going on. The movie consisted of a love hate relationship between Madsen and Argento, Which basically was Madsen insulting her, threatening violence and generally treating her like dirt. She on the other hand loves him, then shes doesn't, then she does, the she desires him, then she loves him again......whats wrong with you woman !!!! <br /><br />The Script is awful, lousy soundtrack and pointless aggressive and crude sexuality which i believe was added to entice some viewers as the movie has little else to offer. I would have given the movie a 1 but it just about managed a 2 with a little excitement in the last 20 minutes. It did actually answer one question in the final few minutes but i am not going to share that, i will make you suffer for the full movie like i did.\"\n",
    "print(text)\n",
    "print('Positive score:', score_new_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluate one positive record\n",
    "\n",
    "text = \"The distribution was good, the subject could have been interessant and comic. whereas, he described the wandering of an old non credible communist looking for loving sensations. Instead of this, the atmosphere is nor lively nor heavy.\"\n",
    "print(text)\n",
    "print('Positive score:', score_new_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf12]",
   "language": "python",
   "name": "conda-env-tf12-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
